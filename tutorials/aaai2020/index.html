<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Graph Neural Networks: Models and Applications</title>
</head>
<body>
<div id="layout-content">
<div id="toptitle">
<h1>Graph Neural Networks: Models and Applications</h1>
<div id="subtitle">&nbsp;&nbsp;</div>
</div>
<h2>Time and Location</h2>
<p><b>Time:</b> 8:30 am - 12:30: am, Friday, February 7, 2020<br /> 
<b>Location:</b> Sutton South<br /></p>
<h2>Abstract</h2>
<p>Graph structured data such as social networks and molecular graphs are ubiquitous in the real world. It is of great research importance to design advanced algorithms for representation learning on graph structured data so that downstream
tasks can be facilitated. Graph Neural Networks (GNNs), which generalize the deep neural network models to graph structured data, pave a new way to effectively learn representations for graph-structured data either from the node level or
the graph level. Thanks to their strong representation learning capability, GNNs have gained practical significance in various applications ranging from recommendation, natural language processing to healthcare. It has become a hot
research topic and attracted increasing attention from the machine learning and data mining community recently. This tutorial of GNNs is timely for AAAI 2020 and covers relevant and interesting topics, including representation learning
on graph structured data using GNNs, the robustness of GNNs, the scalability of GNNs and applications based on GNNs.</p>
<h2>Tutorial Syllabus</h2>
<ol>
<li><p><b>Introduction</b></p>
<ol>
<li><p>Graphs and Graph Structured Data</p>
</li>
<li><p>Tasks on Graph Structured Data</p>
</li>
<li><p>Graph neural networks</p>
</li></ol>
</li>
<li><p><b>Foundations</b></p>
<ol>
<li><p>Basic Graph Theory</p>
</li>
<li><p>Graph Fourier Transform</p>
</li></ol>
</li>
<li><p><b>Models</b></p>
<ol>
<li><p>Spectral-based GNN layers</p>
</li>
<li><p>Spatial-based GNN layers</p>
</li>
<li><p>Pooling Schemes for Graph-level Representation Learning</p>
</li>
<li><p>Graph Neural Networks Based Encoder-Decoder models</p>
</li>
<li><p>Scalable Learning for Graph Neural Networks</p>
</li>
<li><p>Attacks and Robustness of Graph Neural Networks</p>
</li></ol>
</li>
<li><p><b>Applications</b></p>
<ol>
<li><p>Natural Language Processing</p>
</li>
<li><p>Recommendation</p>
</li>
<li><p>Healthcare</p>
</li>
</ol>

</li>
</ol>
<h2>Tutorial slides </h2>
<p><a href="https://drive.google.com/file/d/1rvm6Yq6-Ss4UmxLDIPTReJJkAdcXdhFb/view?usp=sharing">Slides</a></p>
<iframe src="https://onedrive.live.com/embed?cid=B581BE4DA382BCDE&amp;resid=B581BE4DA382BCDE%219983&amp;authkey=AIoywkWzaPgWaiw&amp;em=2&amp;wdAr=1.7777777777777777" width="610px" height="367px" frameborder="0">这是嵌入 <a
target="_blank" href="https://office.com">Microsoft Office</a> 演示文稿，由 <a target="_blank" href="https://office.com/webapps">Office</a> 提供支持。</iframe>
<h2>Presenters</h2>
<table class="imgtable"><tr><td>
<a href="images/yao_ma.jpg"><img src="images/yao_ma.jpg" alt="Image of Yao" width="238px" height="238px" /></a>&nbsp;</td>
<td align="left"><p><a href="http://cse.msu.edu/~mayao4/"><b>Yao Ma</b></a> is a Ph.D. student of Computer Science and Engineering
at Michigan State University. He also works as a research assistant at the Data Science and
Engineering lab (DSE lab) led by Dr. Jiliang Tang. His research interests include network
embedding and graph neural networks for representation learning on graph-structured data.
He has published innovative works in top-tier conferences such as WSDM, ASONAM, ICDM,
SDM, WWW, KDD and IJCAI. Before joining Michigan State University, he obtained
his master’s degree from Eindhoven University of Technology and bachelor’s degree from Zhejiang University.</p>
</td></tr></table>
<table class="imgtable"><tr><td>
<a href="images/wei_jin.jpg"><img src="images/wei_jin.jpg" alt="Image of Wei" width="238px" height="238px" /></a>&nbsp;</td>
<td align="left"><p><a href="https://chandlerbang.github.io/"><b>Wei Jin</b></a> is a first-year Ph.D. student of 
Computer Science and Engineering at Michigan State University (MSU), supervised 
by Dr. Jiliang Tang. His interests lie in Graph Representation Learning. 
Now I work on the area of graph neural network including its theory foundations, 
model robustness and applications.</p>
</td></tr></table>
<table class="imgtable"><tr><td>
<a href="images/jiliang_tang.jpg"><img src="images/jiliang_tang.jpg" alt="Image of Jiliang" width="238px" height="276px" /></a>&nbsp;</td>
<td align="left"><p><a href="https://www.cse.msu.edu/~tangjili/"><b>Jiliang Tang</b></a> is an assistant professor in the computer science and engineering department at Michigan State University since Fall@2016. Before that, he was a research scientist in Yahoo Research and got his PhD from Arizona State
University in 2015. His research interests including social computing, data mining and machine learning and their applications in education. He was the recipients of 2019 NSF Career Award, the 2015 KDD Best Dissertation runner up and 6
best paper awards (or runner-ups) including WSDM2018 and KDD2016. He serves as conference organizers (e.g., KDD, WSDM and SDM) and journal editors (e.g., TKDD). He has published his research in highly ranked journals and top conference
proceedings, which received thousands of citations and extensive media coverage.</p>
</td></tr></table>
<table class="imgtable"><tr><td>
<a href="images/lingfei_wu.jpg"><img src="images/lingfei_wu.jpg" alt="Image of Lingfei" width="238px" height="250px" /></a>&nbsp;</td>
<td align="left"><p><a href="https://sites.google.com/a/email.wm.edu/teddy-lfwu/"><b>Lingfei Wu</b></a> is a Research Staff Member in the IBM AI Foundations Labs, Reasoning group at IBM T. J. Watson Research Center. He earned his Ph.D. degree in computer science from College of William and Mary in August 2016, under the
supervision of Prof. Andreas Stathopoulos. He is a research team leader (consisting of 10+ research staff members) for several research projects (we named AI Challenges inside IBM Research), including Deep Learning on Graphs for AI. He
has served as the PI in IBM for several federal agencies such as DARPA and NSF (more than $1.8M). He is also an IBM Co-PI of the MIT-IBM Watson AI Lab Award (2018 and 2019) for projects themed &ldquo;Intelligent Multi-Scale Design of De Novo
Proteins to Enhance Food Security&rdquo;.</p>
<p>His research interests lie at the intersection of Machine Learning(Deep Learning), Representation Learning, and Natural Language Processing, with a particular emphasis on the fast-growing subjects of Graph Neural Networks and its
extensions on new application domains. Lingfei has published more than 50 top-ranked conference and journal papers, including but not limited to NIPS, ICML, ICLR, AISTATS, KDD, ICDM, NAACL, EMNLP, IJCAI, AAAI, and SIAM Journal on
Scientific Computing. He is also a co-inventor of more than 20 filed US patents. He was the recipients of the Best Paper Award in IEEE ICC&rsquo;19 and KDD workshop on DLG&rsquo;19, and the Best Student Paper Award in AIAED&rsquo;19 and KDD workshop on
DLG&rsquo;19. Lingfei's research has been featured in numerous media outlets, including NatureNews, YahooNews, Venturebeat, TechTalks, SyncedReview, Leiphone, QbitAI, MIT News, IBM Research News, and SIAM News. </p>
</td></tr></table>
<table class="imgtable"><tr><td>
<a href="images/tengfei_ma.jpg"><img src="images/tengfei_ma.jpg" alt="Image of Tengfei" width="238px" height="250px" /></a>&nbsp;</td>
<td align="left"><p><a href="https://sites.google.com/site/matf0123/home"><b>Tengfei Ma</b></a> is currently a research staff member in IBM T. J. Watson Research Center, New York, USA. He joined IBM Research in 2015 and worked in Tokyo Lab for one year and a half.</p>
<p>Prior to IBM, he obtained his PhD degree from the Graduate School of Information Science and Technology, the University of Tokyo, Japan, under the supervision of Prof. Hiroshi Nakagawa. He received his M.S. from Peking University and his B.E. from Tsinghua University, China.</p>
<p>His research interests have spanned a number of different topics in machine learning and natural language processing (NLP) during his study and career, including document summarization, bilingual text mining, Bayesian nonparametrics, deep
learning for education and healthcare. Currently his research is mainly focused on graph neural networks, and he is also interested in other deep learning techniques in healthcare and NLP areas.</p>
</td></tr></table>
<div id="footer">
<div id="footer-text">
Page generated 2020-02-07 10:01:55 EST, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</div>
</body>
</html>
